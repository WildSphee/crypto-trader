{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bd41fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05593b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chan\\Desktop\\crypto-trader\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Chan\\Desktop\\crypto-trader\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Chan\\Desktop\\crypto-trader\\venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at yiyanghkust/finbert-tone.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url  status source  \\\n",
      "13  https://www.federalreserve.gov/monetarypolicy/...  cached  cache   \n",
      "14  https://www.federalreserve.gov/monetarypolicy/...  cached  cache   \n",
      "15  https://www.federalreserve.gov/monetarypolicy/...  cached  cache   \n",
      "16  https://www.federalreserve.gov/monetarypolicy/...  cached  cache   \n",
      "17  https://www.federalreserve.gov/monetarypolicy/...  cached  cache   \n",
      "\n",
      "    word_count  \n",
      "13        8719  \n",
      "14        7501  \n",
      "15        8235  \n",
      "16        7103  \n",
      "17        6947  \n",
      "                                                  url  \\\n",
      "13  https://www.federalreserve.gov/monetarypolicy/...   \n",
      "14  https://www.federalreserve.gov/monetarypolicy/...   \n",
      "15  https://www.federalreserve.gov/monetarypolicy/...   \n",
      "16  https://www.federalreserve.gov/monetarypolicy/...   \n",
      "17  https://www.federalreserve.gov/monetarypolicy/...   \n",
      "\n",
      "                                               title  \\\n",
      "13  Board of Governors of the Federal Reserve System   \n",
      "14  Board of Governors of the Federal Reserve System   \n",
      "15  Board of Governors of the Federal Reserve System   \n",
      "16  Board of Governors of the Federal Reserve System   \n",
      "17  Board of Governors of the Federal Reserve System   \n",
      "\n",
      "                                             checksum  finbert_pos  \\\n",
      "13  9fbaaac9ceccaf2fdb0fb2f789b62b2597064981dba9a3...     0.310820   \n",
      "14  ff985a9f8f417edc7f866895acdb6164a1d201d23a2c2a...     0.283515   \n",
      "15  32b9571cbd9815b96d3301229d90f962969f797b888818...     0.361310   \n",
      "16  fe9ac27267585329ad4f83f8e9b8edabf0a46b569bf531...     0.281421   \n",
      "17  90f029ec6cf4a05a46220c6badcf9eb6af4b03b78e59f3...     0.283485   \n",
      "\n",
      "    finbert_neg  finbert_neutral source  \n",
      "13     0.544551         0.144628   None  \n",
      "14     0.562502         0.153983   None  \n",
      "15     0.456727         0.181963   None  \n",
      "16     0.495345         0.223234   None  \n",
      "17     0.497179         0.219336   None  \n"
     ]
    }
   ],
   "source": [
    "from features.fomc import scrape_fomc_minutes\n",
    "\n",
    "df_pages, df_sent = scrape_fomc_minutes()\n",
    "print(df_pages[[\"url\", \"status\", \"source\", \"word_count\"]].head())\n",
    "print(df_sent.head() if df_sent is not None else \"sentiment disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0ac944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at yiyanghkust/finbert-tone were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at yiyanghkust/finbert-tone.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# this one shd run quick cause cached\n",
    "df_pages2, df_sent2 = scrape_fomc_minutes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa41fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at yiyanghkust/finbert-tone were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at yiyanghkust/finbert-tone.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           finbert_pos_smooth  finbert_neg_smooth  \\\n",
      "ts_utc                                                              \n",
      "2025-06-01 00:00:00+00:00                 NaN                 NaN   \n",
      "2025-06-01 04:00:00+00:00                 NaN                 NaN   \n",
      "2025-06-01 08:00:00+00:00                 NaN                 NaN   \n",
      "2025-06-01 12:00:00+00:00                 NaN                 NaN   \n",
      "2025-06-01 16:00:00+00:00                 NaN                 NaN   \n",
      "\n",
      "                           finbert_neutral_smooth  \\\n",
      "ts_utc                                              \n",
      "2025-06-01 00:00:00+00:00                     NaN   \n",
      "2025-06-01 04:00:00+00:00                     NaN   \n",
      "2025-06-01 08:00:00+00:00                     NaN   \n",
      "2025-06-01 12:00:00+00:00                     NaN   \n",
      "2025-06-01 16:00:00+00:00                     NaN   \n",
      "\n",
      "                           fomc_sentiment_composite_smooth  \\\n",
      "ts_utc                                                       \n",
      "2025-06-01 00:00:00+00:00                              NaN   \n",
      "2025-06-01 04:00:00+00:00                              NaN   \n",
      "2025-06-01 08:00:00+00:00                              NaN   \n",
      "2025-06-01 12:00:00+00:00                              NaN   \n",
      "2025-06-01 16:00:00+00:00                              NaN   \n",
      "\n",
      "                           fomc_sentiment_polarity_smooth  word_count_smooth  \n",
      "ts_utc                                                                        \n",
      "2025-06-01 00:00:00+00:00                             NaN                NaN  \n",
      "2025-06-01 04:00:00+00:00                             NaN                NaN  \n",
      "2025-06-01 08:00:00+00:00                             NaN                NaN  \n",
      "2025-06-01 12:00:00+00:00                             NaN                NaN  \n",
      "2025-06-01 16:00:00+00:00                             NaN                NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chan\\Desktop\\crypto-trader\\features\\fomc.py:317: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  idx = pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "from features.fomc import get_fomc_sentiment\n",
    "\n",
    "df = get_fomc_sentiment(\n",
    "    start=\"2025-06-01\",\n",
    "    end=\"2025-08-15\",\n",
    "    interval=\"4h\",  # same cadence as your crypto DF\n",
    "    lookback_days=3,  # carry meeting signal for 3 days\n",
    "    smooth_kind=\"ema\",\n",
    "    smooth_span=6,\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "# index name is 'ts_utc'\n",
    "# columns like:\n",
    "# ['finbert_pos_smooth','finbert_neg_smooth','finbert_neutral_smooth',\n",
    "#  'fomc_sentiment_composite_smooth','fomc_sentiment_polarity_smooth','word_count_smooth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc117e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
